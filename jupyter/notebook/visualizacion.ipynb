{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ipykernel kafka-python pandas matplotlib folium python-dateutil ipython "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output, IFrame\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "import matplotlib.dates as mdates\n",
    "from kafka import KafkaConsumer\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load medidores data if available\n",
    "medidores_df = pd.DataFrame(columns=['id', 'region', 'lat', 'long'])\n",
    "medidores_path = '/app/medidores.json'\n",
    "if os.path.exists(medidores_path):\n",
    "    try:\n",
    "        with open(medidores_path, 'r') as f:\n",
    "            medidores = json.load(f)\n",
    "        medidores_df = pd.DataFrame(medidores)\n",
    "        logger.info(f\"Loaded {len(medidores_df)} medidores from {medidores_path}.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading medidores.json: {e}\")\n",
    "else:\n",
    "    logger.warning(f\"{medidores_path} not found. Using empty medidores_df.\")\n",
    "\n",
    "# Kafka Consumer Configuration\n",
    "consumer = KafkaConsumer(\n",
    "    'output',\n",
    "    bootstrap_servers='kafka:9092',\n",
    "    auto_offset_reset='latest',\n",
    "    group_id='visualization-group',\n",
    "    value_deserializer=lambda m: json.loads(m.decode('utf-8')),\n",
    ")\n",
    "\n",
    "# Dictionary to store data keyed by (window_start, region)\n",
    "data_dict = {}\n",
    "MAX_RECORDS = 100\n",
    "\n",
    "# Variable to track the last update time\n",
    "last_update_time = time.time()\n",
    "UPDATE_INTERVAL = 30  # seconds\n",
    "\n",
    "def get_color_by_consumption(consumo):\n",
    "    \"\"\"Assign color based on average consumption.\"\"\"\n",
    "    if consumo is None:\n",
    "        return 'blue'\n",
    "    if consumo < 500:\n",
    "        return 'green'\n",
    "    elif consumo < 1000:\n",
    "        return 'orange'\n",
    "    else:\n",
    "        return 'red'\n",
    "\n",
    "def update_dashboard(df):\n",
    "    # Clear the notebook output cell\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # Ensure window_start is datetime\n",
    "    df['window_start'] = pd.to_datetime(df['window_start'], errors='coerce')\n",
    "    df = df.dropna(subset=['window_start'])\n",
    "    if df.empty:\n",
    "        logger.warning(\"No valid data to visualize.\")\n",
    "        return\n",
    "\n",
    "    # Get latest window and filter data for that window\n",
    "    latest_window = df['window_start'].max()\n",
    "    latest_data_window = df[df['window_start'] == latest_window]\n",
    "\n",
    "    # Create Folium map if medidores_df is available\n",
    "    map_html = None\n",
    "    if not medidores_df.empty:\n",
    "        avg_lat = medidores_df['lat'].mean()\n",
    "        avg_long = medidores_df['long'].mean()\n",
    "        m = folium.Map(location=[avg_lat, avg_long], zoom_start=12)\n",
    "        marker_cluster = MarkerCluster().add_to(m)\n",
    "\n",
    "        region_avg = latest_data_window.set_index('region')['avg_consumo'].to_dict()\n",
    "\n",
    "        for _, medidor in medidores_df.iterrows():\n",
    "            region = medidor['region']\n",
    "            avg_consumo_region = region_avg.get(region)\n",
    "            color = get_color_by_consumption(avg_consumo_region)\n",
    "            popup_text = f\"Region: {region}<br>\"\n",
    "            if avg_consumo_region is not None:\n",
    "                popup_text += f\"Avg. Consumo: {avg_consumo_region:.2f} kWh\"\n",
    "            else:\n",
    "                popup_text += \"Avg. Consumo: N/A\"\n",
    "            folium.CircleMarker(\n",
    "                location=[medidor['lat'], medidor['long']],\n",
    "                radius=8,\n",
    "                color=color,\n",
    "                fill=True,\n",
    "                fill_color=color,\n",
    "                popup=popup_text\n",
    "            ).add_to(marker_cluster)\n",
    "\n",
    "        map_html = 'map.html'\n",
    "        m.save(map_html)\n",
    "\n",
    "    # Split historical data by region\n",
    "    historical_samborondon = df[df['region'] == 'Samborondon'].sort_values('window_start')\n",
    "    historical_daule = df[df['region'] == 'Daule'].sort_values('window_start')\n",
    "\n",
    "    # Create a new figure for each update\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(14, 12))\n",
    "\n",
    "    # (0) for map and indicators table\n",
    "    ax_map = axes[0]\n",
    "    ax_map.axis('off')\n",
    "\n",
    "    if map_html:\n",
    "        # Display map in the output cell (not in ax_map)\n",
    "        display(IFrame(map_html, width='500', height='400'))\n",
    "    \n",
    "    ax_table = ax_map\n",
    "    ax_table.axis('off')\n",
    "\n",
    "    table_data = [['Region', 'Avg Consumo', 'Max', 'Min', 'Peak?']]\n",
    "    for _, row in latest_data_window.iterrows():\n",
    "        peak_str = 'Yes' if row['is_peak'] else 'No'\n",
    "        table_data.append([\n",
    "            row['region'],\n",
    "            f\"{row['avg_consumo']:.2f}\",\n",
    "            row['max_consumo'],\n",
    "            row['min_consumo'],\n",
    "            peak_str\n",
    "        ])\n",
    "\n",
    "    tbl = ax_table.table(cellText=table_data, loc='center', cellLoc='center')\n",
    "    tbl.set_fontsize(12)\n",
    "    tbl.scale(1, 2)\n",
    "\n",
    "    # Set up a more automatic locator/formatter for times\n",
    "    locator = mdates.AutoDateLocator()\n",
    "    formatter = mdates.AutoDateFormatter(locator)\n",
    "\n",
    "    # (1) Samborondon Trend\n",
    "    ax_sam = axes[1]\n",
    "    ax_sam.clear()\n",
    "    if not historical_samborondon.empty:\n",
    "        ax_sam.plot(historical_samborondon['window_start'], historical_samborondon['avg_consumo'], marker='o', label='Samborondon')\n",
    "        sam_peaks = historical_samborondon[historical_samborondon['is_peak']]\n",
    "        if not sam_peaks.empty:\n",
    "            ax_sam.scatter(sam_peaks['window_start'], sam_peaks['avg_consumo'], color='red', marker='x', s=100, label='Peak') #PEAK\n",
    "        ax_sam.set_title('Tendencia Consumo Samborondon')\n",
    "        ax_sam.set_xlabel('Tiempo')\n",
    "        ax_sam.set_ylabel('Consumo (kWh)')\n",
    "\n",
    "        ax_sam.xaxis.set_major_locator(locator)\n",
    "        ax_sam.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "        plt.setp(ax_sam.get_xticklabels(), rotation=45, ha='right')\n",
    "        ax_sam.legend()\n",
    "    else:\n",
    "        ax_sam.text(0.5, 0.5, 'No Data Samborondon', ha='center', va='center')\n",
    "        \n",
    "    ax_sam.set_xticks([])\n",
    "    ax_sam.set_xticklabels([])\n",
    "    ax_sam.set_xlabel('')\n",
    "\n",
    "    # (2) Daule Trend\n",
    "    ax_dau = axes[2]\n",
    "    ax_dau.clear()\n",
    "    if not historical_daule.empty:\n",
    "        ax_dau.plot(historical_daule['window_start'], historical_daule['avg_consumo'], marker='o', color='green', label='Daule')\n",
    "        dau_peaks = historical_daule[historical_daule['is_peak']]\n",
    "        if not dau_peaks.empty:\n",
    "            ax_dau.scatter(dau_peaks['window_start'], dau_peaks['avg_consumo'], color='red', marker='x', s=100, label='Peak') #PEAK\n",
    "        ax_dau.set_title('Tendencia Consumo Daule')\n",
    "        ax_dau.set_xlabel('Tiempo')\n",
    "        ax_dau.set_ylabel('Consumo (kWh)')\n",
    "\n",
    "        ax_dau.xaxis.set_major_locator(locator)\n",
    "        ax_dau.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "        plt.setp(ax_dau.get_xticklabels(), rotation=45, ha='right')\n",
    "        ax_dau.legend()\n",
    "    else:\n",
    "        ax_dau.text(0.5, 0.5, 'No Data Daule', ha='center', va='center')\n",
    "\n",
    "    ax_dau.set_xticks([])\n",
    "    ax_dau.set_xticklabels([])\n",
    "    ax_dau.set_xlabel('')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    display(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "try:\n",
    "    logger.info(\"Starting data consumption loop...\")\n",
    "    while True:\n",
    "        message_pack = consumer.poll(timeout_ms=1000, max_records=10)\n",
    "        if not message_pack:\n",
    "            # If no messages, check if it's time to update the dashboard\n",
    "            current_time = time.time()\n",
    "            if (current_time - last_update_time) >= UPDATE_INTERVAL:\n",
    "                # Update the dashboard if we have data\n",
    "                if data_dict:\n",
    "                    df = pd.DataFrame(data_dict.values())\n",
    "                    update_dashboard(df)\n",
    "                    last_update_time = current_time\n",
    "            continue\n",
    "\n",
    "        # Process incoming messages\n",
    "        updated = False\n",
    "        for tp, messages in message_pack.items():\n",
    "            for message in messages:\n",
    "                data = message.value\n",
    "                logger.info(f\"Received data: {data}\")\n",
    "\n",
    "                required_fields = ['window_start', 'window_end', 'region', 'avg_consumo', 'max_consumo', 'min_consumo', 'is_peak']\n",
    "                if not all(field in data for field in required_fields):\n",
    "                    logger.error(f\"Incomplete data received: {data}\")\n",
    "                    continue\n",
    "\n",
    "                # Use (window_start, region) as the key to avoid duplicates\n",
    "                key = (data['window_start'], data['region'])\n",
    "                data_dict[key] = {\n",
    "                    'window_start': data['window_start'],\n",
    "                    'window_end': data['window_end'],\n",
    "                    'region': data['region'],\n",
    "                    'avg_consumo': data['avg_consumo'],\n",
    "                    'max_consumo': data['max_consumo'],\n",
    "                    'min_consumo': data['min_consumo'],\n",
    "                    'is_peak': data['is_peak']\n",
    "                }\n",
    "                updated = True\n",
    "\n",
    "        # Keep only the last MAX_RECORDS entries if needed\n",
    "        if len(data_dict) > MAX_RECORDS:\n",
    "            # sort by window_start\n",
    "            sorted_keys = sorted(data_dict.keys(), key=lambda x: x[0])\n",
    "            while len(data_dict) > MAX_RECORDS:\n",
    "                oldest_key = sorted_keys.pop(0)\n",
    "                del data_dict[oldest_key]\n",
    "\n",
    "        # After processing this batch, check if 30 seconds have passed since last update\n",
    "        current_time = time.time()\n",
    "        if (current_time - last_update_time) >= UPDATE_INTERVAL:\n",
    "            if data_dict:\n",
    "                df = pd.DataFrame(data_dict.values())\n",
    "                update_dashboard(df)\n",
    "            last_update_time = current_time\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    logger.info(\"Visualization stopped by user.\")\n",
    "finally:\n",
    "    consumer.close()\n",
    "    logger.info(\"Kafka consumer closed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
